{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "import tkinter.filedialog as tkfd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Flatten, Dense, Activation,Convolution2D,MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "        image_list=[]\n",
    "        for filename in os.listdir(folder):\n",
    "            img=cv2.imread(os.path.join(folder,filename))\n",
    "            if img is not None:\n",
    "                image_list.append(img)\n",
    "        return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train=load_images(\"Image-Data\\Training Images\")\n",
    "X_Train=np.array(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test=load_images(\"Image-Data\\Testing Images\")\n",
    "X_Test=np.array(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Validation=load_images(\"Image-Data\\Validation Images\")\n",
    "X_Validation=np.array(X_Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Train=pd.read_csv(\"ISIC-2017_Training_Part3_GroundTruth.csv\")\n",
    "data_Test=pd.read_csv(\"ISIC-2017_Test_v2_Part3_GroundTruth.csv\")\n",
    "data_Validation=pd.read_csv(\"ISIC-2017_Validation_Part3_GroundTruth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Train=data_Train.iloc[0:2000,1]\n",
    "data_Test=data_Test.iloc[0:600,1]\n",
    "data_Validation=data_Validation.iloc[0:300,1]\n",
    "\n",
    "y_Train=data_Train\n",
    "y_Test=data_Test\n",
    "y_Validation=data_Validation\n",
    "\n",
    "y_Train=np.array(y_Train)\n",
    "y_Test=np.array(y_Test)\n",
    "y_Validation=np.array(y_Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Train = np_utils.to_categorical(data_Train)\n",
    "y_Test = np_utils.to_categorical(data_Test)\n",
    "y_Validation = np_utils.to_categorical(data_Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network with 6 layers\n",
    "Optimizer=Adam(learning_rate=0.001)\n",
    "objective='binary_crossentropy'\n",
    "def center_normalize(x):\n",
    "    return (x-K.mean(x))/K.std(x)\n",
    "model=Sequential()\n",
    "#input layer\n",
    "model.add(Activation(activation=center_normalize, input_shape=(64, 64,3)))\n",
    "# convolutional layer\n",
    "model.add(Convolution2D(32,5,5,padding='same',activation='relu',data_format='channels_last'))\n",
    "#pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2),data_format='channels_last'))\n",
    "# convolutional layer\n",
    "model.add(Convolution2D(64,3,3,padding='same',activation='relu',data_format='channels_last'))\n",
    "# pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2),data_format='channels_last'))\n",
    "model.add(Flatten())\n",
    "# Relu \n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Sigmoid Fully connected layer\n",
    "model.add(Dense(y_Train.shape[1]))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss=objective,optimizer=Optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10/10 [==============================] - 7s 10ms/step - loss: 0.5664 - accuracy: 0.7465\n",
      "Epoch 2/15\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5154 - accuracy: 0.8130\n",
      "Epoch 3/15\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5018 - accuracy: 0.8130\n",
      "Epoch 4/15\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4903 - accuracy: 0.8130\n",
      "Epoch 5/15\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4824 - accuracy: 0.8130\n",
      "Epoch 6/15\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.8130\n",
      "Epoch 7/15\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.8130\n",
      "Epoch 8/15\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4620 - accuracy: 0.8130\n",
      "Epoch 9/15\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.8135\n",
      "Epoch 10/15\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4483 - accuracy: 0.8155\n",
      "Epoch 11/15\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.8165\n",
      "Epoch 12/15\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.8200\n",
      "Epoch 13/15\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.8230\n",
      "Epoch 14/15\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4225 - accuracy: 0.8240\n",
      "Epoch 15/15\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f067ef080>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(250)\n",
    "model.fit(X_Train,y_Train,batch_size=200,epochs=15,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 6ms/step - loss: 0.5213 - accuracy: 0.8050\n",
      "\n",
      "accuracy: 80.50%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_Test, y_Test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5032 - accuracy: 0.8000\n",
      "\n",
      "accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_Validation, y_Validation)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
